### ğŸš€ **Neural Network Visualization for MNIST Dataset** ğŸ§ ğŸ”  

This project is a **Neural Network implementation with visualization** using **Pygame** for the **MNIST handwritten digits dataset**. It provides a **real-time interactive visualization** of the neural network's layers, weights, activations, and predictions.

https://github.com/user-attachments/assets/23659bfd-a624-4845-aeeb-1456cae798f4

---

## **ğŸ“Œ Features**
âœ… **Train a Multi-Layer Neural Network** with two hidden layers.  
âœ… **Visualize Neurons & Weights** dynamically using **Pygame**.  
âœ… **MNIST Dataset** is loaded via **scikit-learn's `fetch_openml`**.  
âœ… **Tracks Accuracy per Digit** (e.g., how well the model predicts the number "3").  
âœ… **Sparse Weight Visualization** â€“ Shows strong & weak connections in real time.  
âœ… **Adjustable Hyperparameters** â€“ Modify **epochs, learning rate, hidden layers**, etc.  

---

## **ğŸ“‚ Project Structure**
```
ğŸ“¦ neural_network_project
 â”£ ğŸ“‚ .venv/                 # Virtual environment (Python packages)
 â”£ ğŸ“‚ assets/                # (Optional) For storing images, fonts, etc.
 â”£ ğŸ“‚ data/                  # (Optional) Dataset storage
 â”£ ğŸ“œ .gitignore             # Git ignore file for unnecessary files
 â”£ ğŸ“œ data_loader.py         # Loads the MNIST dataset using fetch_openml()
 â”£ ğŸ“œ main.py                # Main script to train and run the visualization
 â”£ ğŸ“œ neural_network.py      # Neural Network implementation (forward & backpropagation)
 â”£ ğŸ“œ requirements.txt       # Dependencies for the project
 â”£ ğŸ“œ utils.py               # Utility functions (loss calculation, weight stats, etc.)
 â”£ ğŸ“œ visualization.py       # Pygame-based visualization for Neural Network
 â”— ğŸ“œ README.md              # Project documentation (this file)
```

---

## **ğŸ“¥ Installation**
### **ğŸ”¹ 1. Clone the Repository**
```sh
git clone https://github.com/yourusername/neural_network_project.git
cd neural_network_project
```

### **ğŸ”¹ 2. Create a Virtual Environment & Activate it**
```sh
python -m venv .venv
```
- **Windows**:
  ```sh
  .venv\Scripts\activate
  ```
- **macOS/Linux**:
  ```sh
  source .venv/bin/activate
  ```

### **ğŸ”¹ 3. Install Required Dependencies**
```sh
pip install -r requirements.txt
```

### **ğŸ”¹ 4. Run the Project**
```sh
python main.py
```

---

## **ğŸ“Š MNIST Dataset**
This project uses **MNIST (Modified National Institute of Standards and Technology)** dataset, which consists of **70,000 handwritten digits (0-9)**.

ğŸ”¹ **Where is the dataset loaded from?**  
ğŸ“Œ The dataset is downloaded **directly from OpenML** using:
```python
from sklearn.datasets import fetch_openml

mnist_data = fetch_openml(name="mnist_784", version=1, as_frame=False)
```
ğŸ”¹ **How is the data processed?**  
âœ… **Normalization:** MNIST images are **28x28 grayscale images**, flattened into **784 pixels**, then normalized to [0,1].  
âœ… **One-hot Encoding:** Labels (0-9) are converted to a one-hot encoded format.  

---

## **ğŸ–¥ï¸ Neural Network Structure**
The model consists of:
- **Input Layer** (784 neurons) â€“ Each neuron represents a pixel.
- **Hidden Layer 1** (1024 neurons, ReLU activation).
- **Hidden Layer 2** (512 neurons, ReLU activation).
- **Output Layer** (10 neurons, Softmax activation for classification).

ğŸ“Œ **Forward Propagation**
```python
self.hidden1_input = np.dot(x, self.weights_input_hidden1) + self.bias_hidden1
self.hidden1_output = np.maximum(0, self.hidden1_input)  # ReLU Activation
self.hidden2_input = np.dot(self.hidden1_output, self.weights_hidden1_hidden2) + self.bias_hidden2
self.hidden2_output = np.maximum(0, self.hidden2_input)  # ReLU Activation
self.output_input = np.dot(self.hidden2_output, self.weights_hidden2_output) + self.bias_output
return self.softmax(self.output_input)
```

ğŸ“Œ **Backpropagation**
```python
output_error = output - y
hidden2_error = np.dot(output_error, self.weights_hidden2_output.T) * (self.hidden2_input > 0)
hidden1_error = np.dot(hidden2_error, self.weights_hidden1_hidden2.T) * (self.hidden1_input > 0)
```

---

## **ğŸ¨ Visualization using Pygame**
The neural network's layers, weights, and activations are **visualized in real time**.  
âœ… **Connections between neurons** are colored based on weight magnitude.  
âœ… **Active neurons glow brighter** depending on activation strength.  
âœ… **Side Panel:** Displays **predictions, loss, accuracy, active neurons**, etc.  

ğŸ–¼ **How to visualize?**  
After training, a **Pygame window opens** showing:
- **Input Layer**
- **Hidden Layers**
- **Output Layer**
- **Prediction & Accuracy Stats**

---

## **ğŸ”® Prediction Process**
1. The model takes a **28x28 handwritten digit image** as input.
2. **Forward propagation** determines the probability of each digit (0-9).
3. The highest probability neuron **determines the predicted digit**.
4. Results are displayed in **Pygame visualization**.

Example **prediction output**:
```plaintext
Epoch 5/30, Test Accuracy: 91.23%
Prediction: 7
Loss: 0.295
Active Neurons: 83.4
```

---

## **âš¡ Technologies Used**
| Feature                 | Library        |
|-------------------------|---------------|
| **Machine Learning**    | NumPy, scikit-learn |
| **Visualization**       | Pygame        |
| **Data Processing**     | Pandas (if needed) |
| **Mathematics**        | NumPy (for matrix operations) |
| **Neural Network**      | Custom implementation in Python |

---

## **ğŸŒŸ Contributing**
Want to improve the project? Follow these steps:

1. **Fork the repository** ğŸ´
2. **Clone your forked repo**:
   ```sh
   git clone https://github.com/yourusername/neural_network_project.git
   ```
3. **Create a feature branch**:
   ```sh
   git checkout -b feature-name
   ```
4. **Commit your changes**:
   ```sh
   git commit -m "Added new feature"
   ```
5. **Push the branch**:
   ```sh
   git push origin feature-name
   ```
6. **Create a Pull Request** ğŸ“©

---

## **ğŸ“œ License**
This project is licensed under the **MIT License** â€“ feel free to modify and use it!  

---

## **ğŸ¯ Future Improvements**
ğŸ”¹ Improve accuracy using **Dropout & Batch Normalization**.  
ğŸ”¹ Implement **Convolutional Neural Networks (CNNs)** for better performance.  
ğŸ”¹ Optimize performance with **GPU acceleration**.  

---


ğŸ”¥ **If you like this project, don't forget to â­ the repo!** ğŸ”¥  
ğŸ‰ Happy Coding! ğŸš€ğŸ‘¨â€ğŸ’»

---

### ğŸ¯ **Git Commands to Upload the Project to GitHub**
```sh
git init  # Initialize Git in the project folder
git add .  # Add all files to commit
git commit -m "Initial commit ğŸš€"
git branch -M main  # Rename branch to main
git remote add origin https://github.com/yourusername/neural_network_project.git  # Add GitHub repo
git push -u origin main  # Push project to GitHub
```
---
