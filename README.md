# ðŸš€ Neural Network for Handwritten Digit Recognition ðŸ§ âœï¸

This project is a **custom-built neural network** that recognizes handwritten digits from the **MNIST dataset** and provides **real-time training visualization**. Users can also **draw a digit**, and the trained model will predict the number. ðŸ”¢âœ¨


---

## ðŸŒŸ Features
âœ… **Train a Fully Connected Neural Network from Scratch** (No TensorFlow or PyTorch!)  
âœ… **Interactive Training Visualization** â€“ Observe neuron activations, weights, and accuracy in real-time ðŸŽ¨ðŸ“Š  
âœ… **Live Drawing Interface** â€“ Draw a digit and get predictions instantly âœï¸ðŸ¤–  
âœ… **Custom Implementation of Forward & Backpropagation** â€“ Full control over weight updates and learning process âš™ï¸  
âœ… **Optimized Training with Mini-Batches** â€“ Speeds up learning and improves accuracy ðŸ“ˆ  
âœ… **Dependencies Managed via requirements.txt** â€“ Easily install all required libraries ðŸ“¦

---

## ðŸ“Š Dataset: MNIST
This project uses the **MNIST dataset**, a collection of **70,000 handwritten digits (0-9)**.

ðŸ”¹ **Where is the dataset loaded from?**  
ðŸ“Œ The dataset is **fetched from OpenML** using `scikit-learn`:
```python
from sklearn.datasets import fetch_openml
mnist_data = fetch_openml(name="mnist_784", version=1, as_frame=False)
```

ðŸ”¹ **How is the data processed?**  
âœ… **Normalization:** Pixel values are scaled between **[0,1]**.  
âœ… **One-hot Encoding:** Converts labels (0-9) into a **binary vector** format.  
âœ… **Training & Testing Split:** The dataset is divided into **60,000 training** and **10,000 test samples**.  

---

## ðŸ“‚ Project Structure
```bash
ðŸ“¦ Neural-Network-Handwritten-Digit-Recognition
 â”£ ðŸ“‚ .venv/                 # Virtual environment (optional)
 â”£ ðŸ“œ .gitignore             # Ignore unnecessary files
 â”£ ðŸ“œ data_loader.py         # Loads and preprocesses the MNIST dataset
 â”£ ðŸ“œ main.py                # Main script: training, visualization, and prediction
 â”£ ðŸ“œ network_visualizer.py  # Visualizes neural network structure using Pygame
 â”£ ðŸ“œ neural_network.py      # Neural Network implementation (forward & backpropagation)
 â”£ ðŸ“œ utils.py               # Digit preprocessing functions (resize, normalize, center)
 â”£ ðŸ“œ requirements.txt       # Required dependencies
 â”£ ðŸ“œ README.md              # Project documentation (this file)
```

---

## ðŸ“¦ Required Libraries
```bash
numpy           # Matrix operations ðŸ§®
pygame          # GUI & visualization ðŸŽ®
matplotlib      # Graphs & plots ðŸ“Š
scipy           # Image processing âš™ï¸
scikit-learn    # Dataset handling ðŸ”
scikit-image    # Resizing & preprocessing ðŸ–¼
```

To install all dependencies, run:
```bash
pip install -r requirements.txt
```

---

## ðŸ›  Installation & Setup
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/Neural-Network-Handwritten-Digit-Recognition.git
cd Neural-Network-Handwritten-Digit-Recognition
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the Training Script
```bash
python main.py
```
ðŸš€ The neural network will start training, and a **visualization window** will open.

---

## ðŸŽ¨ Drawing & Prediction
1. **A Pygame window will appear** where you can draw a digit. âœï¸  
2. **The network processes the image** and predicts the digit. ðŸ§   
3. **The result is displayed in the console.** ðŸŽ¯  

---

## ðŸ— Neural Network Architecture
```
Input Layer (784) â†’ Hidden Layer 1 (512 neurons, ReLU) â†’ Hidden Layer 2 (256 neurons, ReLU) â†’ Output Layer (10, Softmax)
```
ðŸ“Œ **Forward Propagation**
```python
self.hidden1_input = np.dot(x, self.weights_input_hidden1) + self.bias_hidden1
self.hidden1_output = np.maximum(0, self.hidden1_input)  # ReLU Activation
self.hidden2_input = np.dot(self.hidden1_output, self.weights_hidden1_hidden2) + self.bias_hidden2
self.hidden2_output = np.maximum(0, self.hidden2_input)  # ReLU Activation
self.output_input = np.dot(self.hidden2_output, self.weights_hidden2_output) + self.bias_output
return self.softmax(self.output_input)
```

ðŸ“Œ **Backpropagation**
```python
output_error = output - y
hidden2_error = np.dot(output_error, self.weights_hidden2_output.T) * (self.hidden2_input > 0)
hidden1_error = np.dot(hidden2_error, self.weights_hidden1_hidden2.T) * (self.hidden1_input > 0)
```

---

## ðŸ“Š Prediction Accuracy
During training, the model achieves **high accuracy**, and test accuracy typically reaches around **97-99%**. ðŸŽ¯  
Each epoch prints the current accuracy in the console, showing improvement over time:
```plaintext
Epoch 10/20 -> Train Accuracy: 96.57%
Test Accuracy: 97.52%
Epoch 15/20 -> Train Accuracy: 99.38%
Test Accuracy: 97.92%
Epoch 20/20 -> Train Accuracy: 99.83%
Test Accuracy: 97.99%
```

---

## ðŸ”§ Technologies Used
| Feature                 | Library        |
|-------------------------|---------------|
| **Machine Learning**    | NumPy, scikit-learn |
| **Visualization**       | Pygame        |
| **Data Processing**     | Scipy, scikit-image |
| **Mathematics**        | NumPy (Matrix operations) |
| **Neural Network**      | Fully custom Python implementation |

---

---


